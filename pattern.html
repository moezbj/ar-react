<html>

</html>

<head>
    <meta charset="UTF-8">
    <title>Handpose with tfjs</title>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1.0, user-scalable=no">
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>
    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
        }

        #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none;
        }
    </style>
</head>

<body>
    <canvas id="canvas" width=360 height=360></canvas>
    <video id="video" width=360 height=360 autoplay style="display:none"></video>
    <canvas id="overlayCanvas" width=360 height=360></canvas>

    <script>
        let video = document.getElementById("video");
        let canvas = document.getElementById("canvas");
        let overlayCanvas = document.getElementById("overlayCanvas");
        let ctx = canvas.getContext("2d");
        let overlayCtx = overlayCanvas.getContext("2d");
        let hands;
        let detector;
        let image = new Image();
        image.src = "./models/henna.png";
        image.onload = () => {
            console.log("Image loaded successfully");
        };

        let showKeyPoints = true;
        let useFront = false;

        /*  function startVideo() {
             if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                 let mode = useFront ? "user" : "environment";
                 navigator.mediaDevices.getUserMedia({ audio: false, video: { width: 360, height: 360, facingMode: mode } }).then(function (stream) {
                     video.addEventListener("loadedmetadata", loadModel);
                     video.srcObject = stream;
                     video.play();
                     drawCameraIntoCanvas();
                 }).catch(err => {
                     console.error("Error accessing media devices.", err);
                 });
             }
         } */
        function startVideo() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                let constraints = {
                    audio: false,
                    video: {
                        width: { ideal: 360 },
                        height: { ideal: 360 },
                        facingMode: useFront ? "user" : "environment"
                    }
                };

                navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                    video.addEventListener("loadedmetadata", loadModel);
                    video.srcObject = stream;
                    video.play();
                    drawCameraIntoCanvas();
                }).catch(err => {
                    console.error("Error accessing media devices.", err);
                });
            }
        }

        async function loadModel() {
            const model = handPoseDetection.SupportedModels.MediaPipeHands;
            const detectorConfig = {
                runtime: 'mediapipe',
                maxHands: 2,
                solutionPath: "https://cdn.jsdelivr.net/npm/@mediapipe/hands"
            };
            detector = await handPoseDetection.createDetector(model, detectorConfig);
            estimateHands();
        }

        async function estimateHands() {
            const estimationConfig = { flipHorizontal: useFront };
            const rawHands = await detector.estimateHands(video, estimationConfig);
            hands = getKeypoints(rawHands);
            drawHandOverlay();
            window.requestAnimationFrame(estimateHands);
        }

        function drawCameraIntoCanvas() {
            ctx.clearRect(0, 0, 360, 360);  // Clear the canvas each frame
            if (useFront) {
                ctx.clearRect(0, 0, 360, 360);
                ctx.save();
                ctx.scale(-1, 1);
                ctx.translate(-360, 0);
                ctx.drawImage(video, 0, 0, 360, 360);
                ctx.restore();
            } else {
                ctx.drawImage(video, 0, 0, 360, 360);
            }
            window.requestAnimationFrame(drawCameraIntoCanvas);
        }

        function drawHandOverlay() {
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            if (hands.length > 0) {
                let hand = hands[0];
                let palmCenter = hand.keypoints[9];
                console.log('palmCenter', palmCenter)
                if (palmCenter) {
                    let imgWidth = 180;
                    let imgHeight = 180;
                    let centerX = (overlayCanvas.width / 2) - (imgWidth / 2);
                    let centerY = (overlayCanvas.height / 2) - (imgHeight / 2);
                    overlayCtx.drawImage(image, palmCenter[0] / 1000, palmCenter[1] / 1000, imgWidth, imgHeight);
                }
            }

        }

        function getKeypoints(hands) {
            let keypoints = [];
            for (let i = 0; i < hands.length; i += 1) {
                let hand = {};
                let points = [];
                for (let j = 0; j < hands[i].keypoints.length; j += 1) {
                    let keypoint = hands[i].keypoints[j];
                    points.push([keypoint.x * canvas.width, keypoint.y * canvas.height]);
                }
                hand.handedness = hands[i].handedness;
                hand.keypoints = points;
                keypoints.push(hand);
            }
            return keypoints;
        }

        startVideo();  // Start video only after switching backend

    </script>
</body>

</html>