<html>

<head>
    <meta charset="UTF-8">
    <title>Handpose with tfjs</title>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1.0, user-scalable=no">
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>
    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
        }

        body {
            width: 100vw;
            height: 100vh;
        }

        #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none;
            z-index: 0;
        }

        #overlayCanvasHand {
            position: absolute;
            top: 0;
            left: 0;
            background-color: rgba(100, 91, 91, 0.3);
            z-index: 999;
            width: 420px;
            height: 420px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        #btn {
            border-radius: 5px;
            background-color: black;
            color: white;
            border: none;
            z-index: 999;
            padding: 10px 15px 10px 15px;
            margin-top: 25px;
            cursor: pointer;
        }

        #btn:hover {
            background-color: white;
            color: black;
        }

        #text {
            color: rgba(255, 255, 255, 1);
            margin-top: 10px;
            margin-bottom: 10px;
            font-size: larger;
            font-weight: 700;
        }
    </style>
</head>

<body>
    <canvas id="canvas" width=420 height=420></canvas>
    <video id="video" width=420 height=420 autoplay playsinline style="display:none"></video>
    <canvas id="overlayCanvas" width=420 height=420></canvas>
    <div id="overlayCanvasHand" width=420 height=420>
        <img src="./models/hand.png" width="180" height="180" />
        <p id="text">Place your hand here</p>
        <button id="btn">Start</button>
    </div>

    <script>
        let video = document.getElementById("video");
        let canvas = document.getElementById("canvas");
        let overlayCanvas = document.getElementById("overlayCanvas");
        let ctx = canvas.getContext("2d");
        let overlayCtx = overlayCanvas.getContext("2d");
        let overlayCanvas2 = document.getElementById("overlayCanvasHand");

        let loading = true;
        let hands;
        let detector;
        let useFront = false;
        // Load image
        let image = new Image();
        image.src = "./models/henna.png";
        image.onload = () => {
            console.log("Image loaded successfully");
        };

        // Add event listeners
        document.getElementById("btn").addEventListener("click", onclickButton);
        console.log('loading', loading);
        // Start video streaming
        function startVideo() {
            console.log('here....1', loading);

            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                let constraints = {
                    audio: false,
                    video: {
                        width: { ideal: 640, max: 640 },
                        height: { ideal: 480, max: 480 },
                        facingMode: useFront ? "user" : "environment"
                    }
                };

                navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                    video.addEventListener("loadedmetadata", loadModel);
                    video.srcObject = stream;
                    video.play();
                    drawCameraIntoCanvas();
                }).catch(err => {
                    console.error("Error accessing media devices.", err);
                });
            }
        }

        // Draw camera stream to canvas
        function drawCameraIntoCanvas() {
            ctx.clearRect(0, 0, 420, 420);
            if (useFront) {
                ctx.save();
                ctx.scale(-1, 1);
                ctx.translate(-420, 0);
            }
            ctx.drawImage(video, 0, 0, 420, 420);
            if (useFront) ctx.restore();
            setTimeout(drawCameraIntoCanvas, 30);  // Limit to ~33fps
        }

        // Load hand pose model
        async function loadModel() {
            const model = handPoseDetection.SupportedModels.MediaPipeHands;
            const detectorConfig = {
                runtime: 'mediapipe',
                maxHands: 2,
                solutionPath: "https://cdn.jsdelivr.net/npm/@mediapipe/hands"
            };
            detector = await handPoseDetection.createDetector(model, detectorConfig);
            console.log('here....2', loading);


        }

        // Estimate hands
        async function estimateHands() {

            try {
                const estimationConfig = { flipHorizontal: useFront };
                const rawHands = await detector.estimateHands(video, estimationConfig);
                hands = getKeypoints(rawHands);
                console.log('here....3', loading);

                drawHandOverlay();
            } catch (error) {
                console.error("Error estimating hands:", error);
            }
            window.requestAnimationFrame(estimateHands);  // Call next frame
        }

        // Draw hand overlay on canvas
        function drawHandOverlay() {
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            if (hands.length > 0) {
                let hand = hands[0];
                let palmCenter = hand.keypoints[9];
                if (palmCenter) {
                    let imgWidth = 200;
                    let imgHeight = 200;
                    console.log("hahahaha", loading);
                    overlayCtx.drawImage(image, palmCenter[0] / 2000, palmCenter[1] / 800, imgWidth, imgHeight);
                }
            }
        }

        // Extract keypoints from hand data
        function getKeypoints(hands) {
            let keypoints = [];
            for (let i = 0; i < hands.length; i += 1) {
                let hand = {};
                let points = [];
                for (let j = 0; j < hands[i].keypoints.length; j += 1) {
                    let keypoint = hands[i].keypoints[j];
                    points.push([keypoint.x * canvas.width, keypoint.y * canvas.height]);
                }
                hand.handedness = hands[i].handedness;
                hand.keypoints = points;
                keypoints.push(hand);
            }
            return keypoints;
        }

        // Button click handler
        function onclickButton(e) {
            e.preventDefault();  // Prevent any default behavior
            e.stopPropagation();  // Prevent any default behavior
            console.log("Button clicked");
            loading = false;
            overlayCanvas2.style.display = "none";  // Hide the overlayCanvasHand
            estimateHands();

        }

        // Start video when the page loads
        startVideo();
    </script>
</body>

</html>